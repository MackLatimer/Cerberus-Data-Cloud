steps:
  # Step 0: Start PostgreSQL for testing
  - name: 'postgres:13'
    id: 'postgres-test-db'
    env:
      - 'POSTGRES_USER=test_user'
      - 'POSTGRES_PASSWORD=test_password'
      - 'POSTGRES_DB=test_db'
    args: ['-p', '5432']

  # Step 1: Run tests for the backend
  - name: 'python:3.9-slim'
    id: 'run-backend-tests'
    dir: 'cerberus_campaigns_backend'
    entrypoint: 'sh'
    waitFor:
      - 'postgres-test-db'
    env:
      - 'DB_USER=test_user'
      - 'DB_PASS=test_password'
      - 'DB_HOST=postgres-test-db'
      - 'DB_PORT=5432'
      - 'DB_NAME=test_db'
      - 'FLASK_ENV=testing'
    args:
      - '-c'
      - |
        apt-get update && apt-get install -y postgresql-client
        # Wait for Postgres to be ready
        until pg_isready -h localhost -p 5432 -U test_user; do
          echo "Waiting for postgres...";
          sleep 1;
        done;
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pytest

  # Step 2: Build the Docker image for cerberus_report_backend (agenda-api)
  - name: 'gcr.io/kaniko-project/executor:latest'
    id: 'build-report-backend'
    dir: 'cerberus_report_backend'
    waitFor: ['-']
    args: [
      '--destination=us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/agenda-api:$SHORT_SHA',
      '--cache=true',
      '--cache-ttl=24h',
      '--context=.',
      '--dockerfile=Dockerfile'
    ]

  # Step 3: Build the Docker image for cerberus_campaigns_backend (campaigns-api)
  - name: 'gcr.io/kaniko-project/executor:latest'
    id: 'build-campaigns-backend'
    dir: 'cerberus_campaigns_backend'
    waitFor: ['-']
    args: [
      '--destination=us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/campaigns-api:$SHORT_SHA',
      '--cache=true',
      '--cache-ttl=24h',
      '--context=.',
      '--dockerfile=Dockerfile'
    ]

  # Step 4: Build the Docker image for cerberus_frontend (web-frontend)
  - name: 'gcr.io/kaniko-project/executor:latest'
    id: 'build-cerberus-frontend'
    dir: 'cerberus_frontend'
    waitFor: ['-']
    args: [
      '--destination=us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/cerberus-frontend:$SHORT_SHA',
      '--cache=true',
      '--cache-ttl=24h',
      '--context=.',
      '--dockerfile=Dockerfile'
    ]

  # Step 5: Build the Docker image for emmons_frontend (web-frontend)
  - name: 'gcr.io/kaniko-project/executor:latest'
    id: 'build-emmons-frontend'
    dir: 'emmons_frontend'
    waitFor: ['-']
    args: [
      '--destination=us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/emmons-frontend:$SHORT_SHA',
      '--cache=true',
      '--cache-ttl=24h',
      '--context=.',
      '--dockerfile=Dockerfile'
    ]

  # Step 6: Run Cloud SQL Proxy
  - name: 'gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.18.0'
    id: 'cloud-sql-proxy'
    waitFor: ['build-campaigns-backend']
    entrypoint: 'sh'
    args:
      - '-c'
      - '/cloud_sql_proxy --unix-socket=/cloudsql $$DB_CONNECTION_NAME'
    secretEnv: ['DB_CONNECTION_NAME']

  # Step 7: Run Database Migrations using a secret for the DATABASE_URL
  - name: 'gcr.io/google-appengine/exec-wrapper'
    id: 'run-migrations'
    waitFor: ['cloud-sql-proxy']
    args: [
      '-i', 'us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/campaigns-api:$SHORT_SHA',
      '-e', 'FLASK_ENV=production',
      '-e', 'DATABASE_URL=postgresql+psycopg://$$(DB_USER):$$(DB_PASS)@/$$(DB_NAME)?host=/cloudsql/$$(DB_CONNECTION_NAME)',
      '--',
      'flask',
      'db',
      'upgrade'
    ]
    secretEnv: ['DB_USER', 'DB_PASS', 'DB_NAME', 'DB_CONNECTION_NAME']

# List of images to be pushed to Artifact Registry
images:
  - 'us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/agenda-api:$SHORT_SHA'
  - 'us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/campaigns-api:$SHORT_SHA'
  - 'us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/cerberus-frontend:$SHORT_SHA'
  - 'us-south1-docker.pkg.dev/cerberus-data-cloud/cerberus-images/emmons-frontend:$SHORT_SHA'

# Specify the service account for Cloud Build to use for executing these steps
# Ensure this service account has 'Artifact Registry Writer' role for the project or specifically for the 'cerberus-images' repository.
serviceAccount: 'projects/cerberus-data-cloud/serviceAccounts/cerberus-service-account@cerberus-data-cloud.iam.gserviceaccount.com'

# Explicitly set logging options as required when a custom service account is used.
options:
  logging: CLOUD_LOGGING_ONLY

availableSecrets:
  secretManager:
  - versionName: projects/cerberus-data-cloud/secrets/DB_CONNECTION_NAME/versions/latest
    env: 'DB_CONNECTION_NAME'
  - versionName: projects/cerberus-data-cloud/secrets/DB_USER/versions/latest
    env: 'DB_USER'
  - versionName: projects/cerberus-data-cloud/secrets/DB_PASS/versions/latest
    env: 'DB_PASS'
  - versionName: projects/cerberus-data-cloud/secrets/DB_NAME/versions/latest
    env: 'DB_NAME'